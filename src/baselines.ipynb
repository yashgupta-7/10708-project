{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.logging import init_wandb, log\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from utils import train, test\n",
    "from models import GCN, GAT, LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "citeseer = Planetoid(root='.', name='Citeseer')\n",
    "cora = Planetoid(root='.', name='Cora')\n",
    "pubmed = Planetoid(root='.', name='Pubmed')\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "seeds = list(range(5))\n",
    "lr = 0.05\n",
    "epochs = 200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAT/GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = citeseer\n",
    "# model = GCN(dataset.num_features, 16, dataset.num_classes)\n",
    "\n",
    "# dataset = cora\n",
    "# model = GCN(dataset.num_features, 16, dataset.num_classes)\n",
    "\n",
    "# dataset = pubmed\n",
    "# model = GCN(dataset.num_features, 16, dataset.num_classes)\n",
    "\n",
    "# dataset = citeseer\n",
    "# model = GAT(dataset.num_features, 8, dataset.num_classes, heads=8)\n",
    "\n",
    "dataset = cora\n",
    "model = GAT(dataset.num_features, 8, dataset.num_classes, heads=8)\n",
    "\n",
    "# dataset = pubmed\n",
    "# model = GAT(dataset.num_features, 8, dataset.num_classes, heads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "data = dataset[0]\n",
    "for c in data.y.unique():\n",
    "    idx = ((data.y == c) & data.train_mask).nonzero(as_tuple=False).view(-1)\n",
    "    idx = idx[torch.randperm(idx.size(0))]\n",
    "    idx = idx[k:]\n",
    "    data.train_mask[idx] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING FOR SEED = 0\n",
      "Epoch: 025, Loss: 0.7877963185310364, Train: 0.9857, Val: 0.7740, Test: 0.7970\n",
      "Epoch: 050, Loss: 0.5370382070541382, Train: 1.0000, Val: 0.7800, Test: 0.7970\n",
      "Epoch: 075, Loss: 0.7434744834899902, Train: 1.0000, Val: 0.7460, Test: 0.8000\n",
      "Epoch: 100, Loss: 0.6166625022888184, Train: 0.9929, Val: 0.7760, Test: 0.8000\n",
      "Epoch: 125, Loss: 0.6144646406173706, Train: 1.0000, Val: 0.7640, Test: 0.8000\n",
      "Epoch: 150, Loss: 0.6733174324035645, Train: 0.9929, Val: 0.7660, Test: 0.8000\n",
      "Epoch: 175, Loss: 0.7851516604423523, Train: 1.0000, Val: 0.7860, Test: 0.8120\n",
      "Best Val Acc: 0.8040 Test Acc: 0.8120\n",
      "RUNNING FOR SEED = 1\n",
      "Epoch: 025, Loss: 0.8419384360313416, Train: 1.0000, Val: 0.7900, Test: 0.8080\n",
      "Epoch: 050, Loss: 0.6773446202278137, Train: 0.9786, Val: 0.7680, Test: 0.8080\n",
      "Epoch: 075, Loss: 0.6612615585327148, Train: 0.9929, Val: 0.7780, Test: 0.8080\n",
      "Epoch: 100, Loss: 0.6862108111381531, Train: 1.0000, Val: 0.7680, Test: 0.8080\n",
      "Epoch: 125, Loss: 0.9013323187828064, Train: 0.9857, Val: 0.7760, Test: 0.8080\n",
      "Epoch: 150, Loss: 0.9508795738220215, Train: 1.0000, Val: 0.7860, Test: 0.8080\n",
      "Epoch: 175, Loss: 0.6330502033233643, Train: 1.0000, Val: 0.7920, Test: 0.8080\n",
      "Best Val Acc: 0.8040 Test Acc: 0.8080\n",
      "RUNNING FOR SEED = 2\n",
      "Epoch: 025, Loss: 0.8537302613258362, Train: 1.0000, Val: 0.7600, Test: 0.8010\n",
      "Epoch: 050, Loss: 0.6010611653327942, Train: 1.0000, Val: 0.7480, Test: 0.8010\n",
      "Epoch: 075, Loss: 0.8915712833404541, Train: 0.9929, Val: 0.7740, Test: 0.8010\n",
      "Epoch: 100, Loss: 0.7835798263549805, Train: 1.0000, Val: 0.7740, Test: 0.8010\n",
      "Epoch: 125, Loss: 0.6128168702125549, Train: 0.9857, Val: 0.7680, Test: 0.7880\n",
      "Epoch: 150, Loss: 1.00404953956604, Train: 1.0000, Val: 0.7480, Test: 0.7880\n",
      "Epoch: 175, Loss: 0.694702684879303, Train: 0.9929, Val: 0.7680, Test: 0.7880\n",
      "Best Val Acc: 0.7960 Test Acc: 0.7880\n",
      "RUNNING FOR SEED = 3\n",
      "Epoch: 025, Loss: 0.9390945434570312, Train: 1.0000, Val: 0.7440, Test: 0.7860\n",
      "Epoch: 050, Loss: 0.8033212423324585, Train: 1.0000, Val: 0.7700, Test: 0.7840\n",
      "Epoch: 075, Loss: 0.7279413342475891, Train: 1.0000, Val: 0.7700, Test: 0.7840\n",
      "Epoch: 100, Loss: 0.6899141669273376, Train: 0.9929, Val: 0.7540, Test: 0.7840\n",
      "Epoch: 125, Loss: 0.8454784154891968, Train: 0.9929, Val: 0.7600, Test: 0.7840\n",
      "Epoch: 150, Loss: 1.0099151134490967, Train: 1.0000, Val: 0.7340, Test: 0.7840\n",
      "Epoch: 175, Loss: 0.9491698145866394, Train: 0.9929, Val: 0.7460, Test: 0.7840\n",
      "Best Val Acc: 0.7880 Test Acc: 0.7840\n",
      "RUNNING FOR SEED = 4\n",
      "Epoch: 025, Loss: 1.0354200601577759, Train: 0.9929, Val: 0.7460, Test: 0.8100\n",
      "Epoch: 050, Loss: 0.7044339179992676, Train: 1.0000, Val: 0.7460, Test: 0.8100\n",
      "Epoch: 075, Loss: 0.8137537240982056, Train: 0.9929, Val: 0.7480, Test: 0.8100\n",
      "Epoch: 100, Loss: 0.6593409776687622, Train: 1.0000, Val: 0.7680, Test: 0.8100\n",
      "Epoch: 125, Loss: 0.8169848918914795, Train: 0.9929, Val: 0.7580, Test: 0.8100\n",
      "Epoch: 150, Loss: 0.5308864712715149, Train: 0.9929, Val: 0.7600, Test: 0.7950\n",
      "Epoch: 175, Loss: 0.609340250492096, Train: 1.0000, Val: 0.7620, Test: 0.7950\n",
      "Best Val Acc: 0.7880 Test Acc: 0.7950\n",
      "Average Val Acc / Average Test Acc: 0.7960 / 0.7974\n"
     ]
    }
   ],
   "source": [
    "av_val_acc = av_test_acc = 0\n",
    "state_dict = model.state_dict().copy()\n",
    "\n",
    "for seed in seeds:\n",
    "    print(\"RUNNING FOR SEED =\", seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # model.load_state_dict(state_dict)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "    best_val_acc = final_test_acc = 0\n",
    "    for epoch in range(1, 200):\n",
    "        loss = train(model, data, optimizer, scheduler=None, loss='cross_entropy')\n",
    "        train_acc, val_acc, tmp_test_acc = test(model, data)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "        if epoch % 25 == 0:\n",
    "            log(Epoch=epoch, Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
    "    print(f'Best Val Acc: {best_val_acc:.4f}', f'Test Acc: {test_acc:.4f}')\n",
    "    av_val_acc += best_val_acc\n",
    "    av_test_acc += test_acc\n",
    "    \n",
    "print(f'Average Val Acc / Average Test Acc: {av_val_acc / len(seeds):.4f} / {av_test_acc / len(seeds):.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING FOR SEED = 42\n",
      "Best Val Acc: 0.7220 Test Acc: 0.7150 Best l: 16 Best a: 0.99\n",
      "RUNNING FOR SEED = 2021\n",
      "Best Val Acc: 0.7220 Test Acc: 0.7150 Best l: 16 Best a: 0.99\n",
      "RUNNING FOR SEED = 1234\n",
      "Best Val Acc: 0.7220 Test Acc: 0.7150 Best l: 16 Best a: 0.99\n",
      "Average Val Acc / Average Test Acc: 0.7220 / 0.7150\n"
     ]
    }
   ],
   "source": [
    "av_val_acc = av_test_acc = 0\n",
    "\n",
    "for seed in seeds:\n",
    "    print(\"RUNNING FOR SEED =\", seed)\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    best_val_acc = final_test_acc = 0\n",
    "    best_l = best_a = 0\n",
    "\n",
    "    for l in [1, 2, 4, 8, 16, 32]:\n",
    "        for a in [0.05, 0.1, 0.3, 0.6, 0.8, 0.9, 0.95, 0.99, 1]:\n",
    "            model = LP(num_layers=l, alpha=a)\n",
    "            outs = model.train(dataset)\n",
    "            train_acc, val_acc, tmp_test_acc = model.test()\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                test_acc = tmp_test_acc\n",
    "                best_l = l\n",
    "                best_a = a\n",
    "    print(f'Best Val Acc: {best_val_acc:.4f}', f'Test Acc: {test_acc:.4f}', f'Best l: {best_l}', f'Best a: {best_a}')\n",
    "    av_test_acc += test_acc\n",
    "    av_val_acc += best_val_acc    \n",
    "print(f'Average Val Acc / Average Test Acc: {av_val_acc / len(seeds):.4f} / {av_test_acc / len(seeds):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fe8eaf950b0cf64c1b70de22759d9a144a2595c541b4003711edd1f96d908e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
