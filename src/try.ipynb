{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "import random\n",
    "random.seed(seed)\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.logging import init_wandb, log\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from utils import train, test, edgeindex2adj\n",
    "from models import GCN, GAT, LP\n",
    "citeseer = Planetoid(root='.', name='Citeseer')\n",
    "cora = Planetoid(root='.', name='Cora')\n",
    "pubmed = Planetoid(root='.', name='Pubmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = citeseer\n",
    "# model = GCN(dataset.num_features, 24, dataset.num_classes)\n",
    "\n",
    "# dataset = cora\n",
    "# model = GCN(dataset.num_features, 8, dataset.num_classes)\n",
    "\n",
    "# dataset = pubmed\n",
    "# model = GCN(dataset.num_features, 8, dataset.num_classes)\n",
    "\n",
    "# dataset = citeseer\n",
    "# model = GAT(dataset.num_features, 8, dataset.num_classes, heads=4)\n",
    "\n",
    "# dataset = cora\n",
    "# model = GAT(dataset.num_features, 8, dataset.num_classes, heads=4)\n",
    "\n",
    "# dataset = pubmed\n",
    "# model = GAT(dataset.num_features, 8, dataset.num_classes, heads=4)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ALP, GCN\n",
    "dataset = cora\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# take k random training nodes for each class\n",
    "k = 3\n",
    "for c in data.y.unique():\n",
    "    idx = ((data.y == c) & data.train_mask).nonzero(as_tuple=False).view(-1)\n",
    "    idx = idx[torch.randperm(idx.size(0))]\n",
    "    idx = idx[k:]\n",
    "    data.train_mask[idx] = False\n",
    "\n",
    "print(data.train_mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Loss: 1.8628408908843994, Train: 0.3810, Val: 0.1580, Test: 0.2980\n",
      "Epoch: 050, Loss: 1.802296757698059, Train: 0.3810, Val: 0.1160, Test: 0.2980\n",
      "Epoch: 075, Loss: 1.7939027547836304, Train: 0.3810, Val: 0.0740, Test: 0.2980\n",
      "Epoch: 100, Loss: 1.793192744255066, Train: 0.3810, Val: 0.1580, Test: 0.2980\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yashgupta/Desktop/10708-project/src/try.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yashgupta/Desktop/10708-project/src/try.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m250\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yashgupta/Desktop/10708-project/src/try.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     loss \u001b[39m=\u001b[39m train(model, data, optimizer, scheduler\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msmooth_label\u001b[39m\u001b[39m'\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yashgupta/Desktop/10708-project/src/try.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     train_acc, val_acc, tmp_test_acc \u001b[39m=\u001b[39m test(model, data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yashgupta/Desktop/10708-project/src/try.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mif\u001b[39;00m val_acc \u001b[39m>\u001b[39m best_val_acc:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yashgupta/Desktop/10708-project/src/try.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         best_val_acc \u001b[39m=\u001b[39m val_acc\n",
      "File \u001b[0;32m~/Desktop/10708-project/src/utils.py:58\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest\u001b[39m(model, data): \u001b[39m# get accuracy on train, val, and test sets\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> 58\u001b[0m     pred \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39;49medge_index)\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     59\u001b[0m     accs \u001b[39m=\u001b[39m []\n\u001b[1;32m     60\u001b[0m     \u001b[39mfor\u001b[39;00m mask \u001b[39min\u001b[39;00m [data\u001b[39m.\u001b[39mtrain_mask, data\u001b[39m.\u001b[39mval_mask, data\u001b[39m.\u001b[39mtest_mask]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/10708-project/src/models.py:16\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, edge_index: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     14\u001b[0m     \u001b[39m# x: Node feature matrix of shape [num_nodes, in_channels]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[39m# edge_index: Graph connectivity matrix of shape [2, num_edges]\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index)\u001b[39m.\u001b[39mrelu()\n\u001b[1;32m     17\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x, edge_index)\n\u001b[1;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:229\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m             edge_index \u001b[39m=\u001b[39m cache\n\u001b[0;32m--> 229\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin(x)\n\u001b[1;32m    231\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m    232\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, edge_weight\u001b[39m=\u001b[39medge_weight,\n\u001b[1;32m    233\u001b[0m                      size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py310/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py:132\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    128\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run for 5 seeds\n",
    "av_acc = 0\n",
    "\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    model = GCN(dataset.num_features, 8, dataset.num_classes)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=50, min_lr=0.0001)\n",
    "\n",
    "    best_val_acc = final_test_acc = 0\n",
    "    for epoch in range(1, 250):\n",
    "        loss = train(model, data, optimizer, scheduler=None, loss='smooth_label', alpha=20)\n",
    "        train_acc, val_acc, tmp_test_acc = test(model, data)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "        if epoch % 25 == 0:\n",
    "            log(Epoch=epoch, Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
    "    print(f'Best Val Acc: {best_val_acc:.4f}', f'Test Acc: {test_acc:.4f}')\n",
    "    av_acc += test_acc\n",
    "print(f'Average Test Acc: {av_acc/5:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 025, Loss: 0.1498504877090454, Train: 1.0000, Val: 0.4900, Test: 0.5050\n",
      "Epoch: 050, Loss: 0.00931228045374155, Train: 1.0000, Val: 0.5380, Test: 0.5520\n",
      "Epoch: 075, Loss: 0.007171915378421545, Train: 1.0000, Val: 0.5620, Test: 0.5710\n",
      "Epoch: 100, Loss: 0.007477668579667807, Train: 1.0000, Val: 0.5600, Test: 0.5710\n",
      "Epoch: 125, Loss: 0.007068636827170849, Train: 1.0000, Val: 0.5620, Test: 0.5710\n",
      "Best Val Acc: 0.5740 Test Acc: 0.5910\n",
      "Epoch: 025, Loss: 0.0841929242014885, Train: 1.0000, Val: 0.4880, Test: 0.5240\n",
      "Epoch: 050, Loss: 0.009557830169796944, Train: 1.0000, Val: 0.5300, Test: 0.5490\n",
      "Epoch: 075, Loss: 0.007854974828660488, Train: 1.0000, Val: 0.5440, Test: 0.5590\n",
      "Epoch: 100, Loss: 0.007982530631124973, Train: 1.0000, Val: 0.5500, Test: 0.5620\n",
      "Epoch: 125, Loss: 0.007707900833338499, Train: 1.0000, Val: 0.5620, Test: 0.5790\n",
      "Best Val Acc: 0.5820 Test Acc: 0.5890\n",
      "Epoch: 025, Loss: 0.1472441405057907, Train: 1.0000, Val: 0.4940, Test: 0.4930\n",
      "Epoch: 050, Loss: 0.009941385127604008, Train: 1.0000, Val: 0.5720, Test: 0.5810\n",
      "Epoch: 075, Loss: 0.007330987602472305, Train: 1.0000, Val: 0.5660, Test: 0.5810\n",
      "Epoch: 100, Loss: 0.0077163539826869965, Train: 1.0000, Val: 0.5760, Test: 0.5980\n",
      "Epoch: 125, Loss: 0.007385372184216976, Train: 1.0000, Val: 0.5900, Test: 0.6010\n",
      "Best Val Acc: 0.5960 Test Acc: 0.6070\n",
      "Epoch: 025, Loss: 0.41486209630966187, Train: 0.9048, Val: 0.3260, Test: 0.3410\n",
      "Epoch: 050, Loss: 0.020769458264112473, Train: 1.0000, Val: 0.5440, Test: 0.5430\n",
      "Epoch: 075, Loss: 0.008341072127223015, Train: 1.0000, Val: 0.5860, Test: 0.5910\n",
      "Epoch: 100, Loss: 0.007824216969311237, Train: 1.0000, Val: 0.5820, Test: 0.5910\n",
      "Epoch: 125, Loss: 0.007432083133608103, Train: 1.0000, Val: 0.5880, Test: 0.5910\n",
      "Best Val Acc: 0.5920 Test Acc: 0.6210\n",
      "Epoch: 025, Loss: 0.36480623483657837, Train: 1.0000, Val: 0.4420, Test: 0.4220\n",
      "Epoch: 050, Loss: 0.027651485055685043, Train: 1.0000, Val: 0.5380, Test: 0.5240\n",
      "Epoch: 075, Loss: 0.011899203062057495, Train: 1.0000, Val: 0.5460, Test: 0.5360\n",
      "Epoch: 100, Loss: 0.010590321384370327, Train: 1.0000, Val: 0.5640, Test: 0.5470\n",
      "Epoch: 125, Loss: 0.009806178510189056, Train: 1.0000, Val: 0.5760, Test: 0.5530\n",
      "Best Val Acc: 0.5820 Test Acc: 0.5830\n",
      "Average Test Acc: 0.5982\n"
     ]
    }
   ],
   "source": [
    "# run for 5 seeds\n",
    "av_acc = 0\n",
    "\n",
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    model = GCN(dataset.num_features, 8, dataset.num_classes)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=50, min_lr=0.0001)\n",
    "\n",
    "    best_val_acc = final_test_acc = 0\n",
    "    for epoch in range(1, 150):\n",
    "        loss = train(model, data, optimizer, scheduler=scheduler, loss='cross_entropy')\n",
    "        train_acc, val_acc, tmp_test_acc = test(model, data)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "        if epoch % 25 == 0:\n",
    "            log(Epoch=epoch, Loss=loss, Train=train_acc, Val=val_acc, Test=test_acc)\n",
    "    print(f'Best Val Acc: {best_val_acc:.4f}', f'Test Acc: {test_acc:.4f}')\n",
    "    av_acc += test_acc\n",
    "print(f'Average Test Acc: {av_acc/5:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10556])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = int(dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data.x.shape[0]\n",
    "counts = np.zeros((n,num_classes))\n",
    "for edge in data.edge_index.T:\n",
    "    counts[edge[0]][data.y[edge[1]]] +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = edgeindex2adj(data.edge_index, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(data.x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.detach().numpy().argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_label_smooth_node_counts = 0\n",
    "total_nodes = 0\n",
    "non_label_smooth_nodes = []\n",
    "for i in range(n):\n",
    "    if data.val_mask[i]:\n",
    "        if preds[i]!=data.y[i]:\n",
    "            if counts[i][data.y[i]] == adj[i].sum() and adj[i].sum() > 1:\n",
    "                non_label_smooth_node_counts +=1\n",
    "                non_label_smooth_nodes.append(i)\n",
    "        total_nodes +=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj[160].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, tensor(0))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[164], data.y[164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 7., 0., 0., 0.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_label_smooth_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[160,\n",
       " 161,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 172,\n",
       " 240,\n",
       " 254,\n",
       " 267,\n",
       " 299,\n",
       " 354,\n",
       " 365,\n",
       " 380,\n",
       " 404,\n",
       " 411,\n",
       " 432,\n",
       " 433,\n",
       " 477,\n",
       " 512,\n",
       " 571,\n",
       " 578,\n",
       " 614,\n",
       " 618,\n",
       " 634]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_label_smooth_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 2. 0. 0. 0.]\n",
      "696 tensor(3)\n",
      "1570 tensor(3)\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "for i in [571]:\n",
    "    print(counts[i])\n",
    "    for j in G.neighbors(i):\n",
    "        print(j, data.y[j])\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 247 elements, which is inconsistent with 'x' and 'y' with size 223.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kousi\\Documents\\cmu\\courses\\10708\\project\\code\\10708-project\\src\\try.ipynb Cell 21\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kousi/Documents/cmu/courses/10708/project/code/10708-project/src/try.ipynb#X55sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# Draw graph with node color and smaller size\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kousi/Documents/cmu/courses/10708/project/code/10708-project/src/try.ipynb#X55sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# nx.draw(new_G, pos = pos, node_color=node_color, node_size=node_sizes, width=0.6, edgecolors = node_border_color, node_shape=node_shape, linewidths=node_border_width)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kousi/Documents/cmu/courses/10708/project/code/10708-project/src/try.ipynb#X55sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m nx\u001b[39m.\u001b[39mdraw_networkx_nodes(new_G, pos\u001b[39m=\u001b[39mpos, nodelist\u001b[39m=\u001b[39mnon_label_smooth_nodes, node_color \u001b[39m=\u001b[39m [color_map[preds[label]] \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m non_label_smooth_nodes], node_size\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m, node_shape\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m, linewidths\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, edgecolors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kousi/Documents/cmu/courses/10708/project/code/10708-project/src/try.ipynb#X55sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m nx\u001b[39m.\u001b[39mdraw_networkx_nodes(new_G, pos \u001b[39m=\u001b[39m pos, nodelist \u001b[39m=\u001b[39m [label \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m node_labels \u001b[39mif\u001b[39;00m label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m non_label_smooth_nodes], node_color\u001b[39m=\u001b[39mnode_color, node_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, node_shape\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m, linewidths\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kousi/Documents/cmu/courses/10708/project/code/10708-project/src/try.ipynb#X55sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m nx\u001b[39m.\u001b[39mdraw_networkx_edges(new_G, pos\u001b[39m=\u001b[39mpos, width\u001b[39m=\u001b[39m\u001b[39m0.6\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kousi/Documents/cmu/courses/10708/project/code/10708-project/src/try.ipynb#X55sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:462\u001b[0m, in \u001b[0;36mdraw_networkx_nodes\u001b[1;34m(G, pos, nodelist, node_size, node_color, node_shape, alpha, cmap, vmin, vmax, ax, linewidths, edgecolors, label, margins)\u001b[0m\n\u001b[0;32m    459\u001b[0m     node_color \u001b[39m=\u001b[39m apply_alpha(node_color, alpha, nodelist, cmap, vmin, vmax)\n\u001b[0;32m    460\u001b[0m     alpha \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m node_collection \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49mscatter(\n\u001b[0;32m    463\u001b[0m     xy[:, \u001b[39m0\u001b[39;49m],\n\u001b[0;32m    464\u001b[0m     xy[:, \u001b[39m1\u001b[39;49m],\n\u001b[0;32m    465\u001b[0m     s\u001b[39m=\u001b[39;49mnode_size,\n\u001b[0;32m    466\u001b[0m     c\u001b[39m=\u001b[39;49mnode_color,\n\u001b[0;32m    467\u001b[0m     marker\u001b[39m=\u001b[39;49mnode_shape,\n\u001b[0;32m    468\u001b[0m     cmap\u001b[39m=\u001b[39;49mcmap,\n\u001b[0;32m    469\u001b[0m     vmin\u001b[39m=\u001b[39;49mvmin,\n\u001b[0;32m    470\u001b[0m     vmax\u001b[39m=\u001b[39;49mvmax,\n\u001b[0;32m    471\u001b[0m     alpha\u001b[39m=\u001b[39;49malpha,\n\u001b[0;32m    472\u001b[0m     linewidths\u001b[39m=\u001b[39;49mlinewidths,\n\u001b[0;32m    473\u001b[0m     edgecolors\u001b[39m=\u001b[39;49medgecolors,\n\u001b[0;32m    474\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[0;32m    475\u001b[0m )\n\u001b[0;32m    476\u001b[0m ax\u001b[39m.\u001b[39mtick_params(\n\u001b[0;32m    477\u001b[0m     axis\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    478\u001b[0m     which\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m     labelleft\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    483\u001b[0m )\n\u001b[0;32m    485\u001b[0m \u001b[39mif\u001b[39;00m margins \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1414\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4387\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4384\u001b[0m \u001b[39mif\u001b[39;00m edgecolors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4385\u001b[0m     orig_edgecolor \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   4386\u001b[0m c, colors, edgecolors \u001b[39m=\u001b[39m \\\n\u001b[1;32m-> 4387\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_scatter_color_args(\n\u001b[0;32m   4388\u001b[0m         c, edgecolors, kwargs, x\u001b[39m.\u001b[39;49msize,\n\u001b[0;32m   4389\u001b[0m         get_next_color_func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_patches_for_fill\u001b[39m.\u001b[39;49mget_next_color)\n\u001b[0;32m   4391\u001b[0m \u001b[39mif\u001b[39;00m plotnonfinite \u001b[39mand\u001b[39;00m colors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4392\u001b[0m     c \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_invalid(c)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4237\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[1;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[0;32m   4233\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4234\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(colors) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, xsize):\n\u001b[0;32m   4235\u001b[0m             \u001b[39m# NB: remember that a single color is also acceptable.\u001b[39;00m\n\u001b[0;32m   4236\u001b[0m             \u001b[39m# Besides *colors* will be an empty array if c == 'none'.\u001b[39;00m\n\u001b[1;32m-> 4237\u001b[0m             \u001b[39mraise\u001b[39;00m invalid_shape_exception(\u001b[39mlen\u001b[39m(colors), xsize)\n\u001b[0;32m   4238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4239\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# use cmap, norm after collection is created\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'c' argument has 247 elements, which is inconsistent with 'x' and 'y' with size 223."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "G.add_nodes_from(range(data.num_nodes))\n",
    "\n",
    "edge_index = data.edge_index.t().tolist()\n",
    "\n",
    "G.add_edges_from(edge_index)\n",
    "\n",
    "node_labels = []\n",
    "level_1_nodes = []\n",
    "for i in non_label_smooth_nodes:\n",
    "    for j in G.neighbors(i):\n",
    "        level_1_nodes.append(j)\n",
    "for i in level_1_nodes:\n",
    "    for j in G.neighbors(i):\n",
    "        node_labels.append(j)\n",
    "node_labels = list(set(node_labels + level_1_nodes + non_label_smooth_nodes))\n",
    "new_G = nx.Graph()\n",
    "new_G.add_nodes_from(node_labels)\n",
    "\n",
    "new_edge_index = []\n",
    "for i in node_labels:\n",
    "    for j in G.neighbors(i):\n",
    "        if j in node_labels:\n",
    "            new_edge_index.append([i,j])\n",
    "new_G.add_edges_from(new_edge_index)\n",
    "\n",
    "\n",
    "# Get node labels\n",
    "# node_labels = data.y.tolist()\n",
    "\n",
    "# Set node color by labels\n",
    "color_map = [\"red\", \"green\", \"blue\", \"yellow\", \"brown\", \"purple\", \"pink\", \"orange\", \"grey\"]\n",
    "node_color = [color_map[data.y[label]] if label not in non_label_smooth_nodes else color_map[preds[label]] for label in node_labels]\n",
    "node_sizes = [150 if label in non_label_smooth_nodes else 20 for label in node_labels]\n",
    "pos = nx.spring_layout(new_G, k=0.2)\n",
    "highlight_border_color = 'black'\n",
    "node_border_color = [highlight_border_color if label in non_label_smooth_nodes else 'none' for label in node_labels]\n",
    "node_border_width = [10 if label in non_label_smooth_nodes else 0 for label in node_labels]\n",
    "node_shapes = ['s' if label in non_label_smooth_nodes else 'o' for label in node_labels]\n",
    "# Draw graph with node color and smaller size\n",
    "# nx.draw(new_G, pos = pos, node_color=node_color, node_size=node_sizes, width=0.6, edgecolors = node_border_color, node_shape=node_shape, linewidths=node_border_width)\n",
    "nx.draw_networkx_nodes(new_G, pos=pos, nodelist=non_label_smooth_nodes, node_color = [color_map[preds[label]] for label in non_label_smooth_nodes], node_size=150, node_shape='s', linewidths=1, edgecolors='black')\n",
    "nx.draw_networkx_nodes(new_G, pos = pos, nodelist = [label for label in node_labels if label not in non_label_smooth_nodes], node_color=[color_map[data.y[label]] for label in node_labels if label not in non_label_smooth_nodes], node_size=20, node_shape='o', linewidths=0)\n",
    "nx.draw_networkx_edges(new_G, pos=pos, width=0.6, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[512,\n",
       " 2,\n",
       " 1542,\n",
       " 519,\n",
       " 2569,\n",
       " 1039,\n",
       " 1556,\n",
       " 1558,\n",
       " 1046,\n",
       " 1051,\n",
       " 1054,\n",
       " 1055,\n",
       " 1056,\n",
       " 1570,\n",
       " 1574,\n",
       " 40,\n",
       " 553,\n",
       " 1065,\n",
       " 2601,\n",
       " 1577,\n",
       " 45,\n",
       " 2606,\n",
       " 1583,\n",
       " 1072,\n",
       " 2609,\n",
       " 566,\n",
       " 2617,\n",
       " 1082,\n",
       " 571,\n",
       " 1597,\n",
       " 574,\n",
       " 578,\n",
       " 68,\n",
       " 71,\n",
       " 1095,\n",
       " 1096,\n",
       " 1099,\n",
       " 588,\n",
       " 77,\n",
       " 1105,\n",
       " 87,\n",
       " 88,\n",
       " 1630,\n",
       " 1633,\n",
       " 1635,\n",
       " 614,\n",
       " 1127,\n",
       " 618,\n",
       " 1131,\n",
       " 118,\n",
       " 634,\n",
       " 1149,\n",
       " 638,\n",
       " 2186,\n",
       " 2187,\n",
       " 1166,\n",
       " 1170,\n",
       " 659,\n",
       " 661,\n",
       " 151,\n",
       " 1176,\n",
       " 1692,\n",
       " 668,\n",
       " 670,\n",
       " 160,\n",
       " 673,\n",
       " 1697,\n",
       " 161,\n",
       " 166,\n",
       " 167,\n",
       " 1704,\n",
       " 681,\n",
       " 168,\n",
       " 172,\n",
       " 1709,\n",
       " 179,\n",
       " 2227,\n",
       " 2229,\n",
       " 2230,\n",
       " 2228,\n",
       " 696,\n",
       " 1211,\n",
       " 1221,\n",
       " 201,\n",
       " 1239,\n",
       " 215,\n",
       " 219,\n",
       " 737,\n",
       " 743,\n",
       " 232,\n",
       " 745,\n",
       " 240,\n",
       " 756,\n",
       " 1269,\n",
       " 251,\n",
       " 253,\n",
       " 2302,\n",
       " 254,\n",
       " 256,\n",
       " 1475,\n",
       " 1476,\n",
       " 260,\n",
       " 266,\n",
       " 267,\n",
       " 1803,\n",
       " 271,\n",
       " 1812,\n",
       " 277,\n",
       " 1300,\n",
       " 792,\n",
       " 2498,\n",
       " 288,\n",
       " 291,\n",
       " 808,\n",
       " 2345,\n",
       " 2346,\n",
       " 2347,\n",
       " 2348,\n",
       " 2349,\n",
       " 812,\n",
       " 299,\n",
       " 814,\n",
       " 1484,\n",
       " 1839,\n",
       " 816,\n",
       " 1332,\n",
       " 300,\n",
       " 1334,\n",
       " 314,\n",
       " 1488,\n",
       " 320,\n",
       " 1859,\n",
       " 2373,\n",
       " 1999,\n",
       " 2508,\n",
       " 842,\n",
       " 1869,\n",
       " 1870,\n",
       " 335,\n",
       " 2383,\n",
       " 1873,\n",
       " 2382,\n",
       " 1875,\n",
       " 1876,\n",
       " 2387,\n",
       " 1363,\n",
       " 2386,\n",
       " 1879,\n",
       " 354,\n",
       " 365,\n",
       " 366,\n",
       " 878,\n",
       " 885,\n",
       " 1399,\n",
       " 888,\n",
       " 380,\n",
       " 893,\n",
       " 1406,\n",
       " 899,\n",
       " 2437,\n",
       " 2438,\n",
       " 391,\n",
       " 1413,\n",
       " 1931,\n",
       " 1933,\n",
       " 397,\n",
       " 1423,\n",
       " 1936,\n",
       " 401,\n",
       " 402,\n",
       " 1940,\n",
       " 1941,\n",
       " 404,\n",
       " 2453,\n",
       " 1434,\n",
       " 411,\n",
       " 924,\n",
       " 2462,\n",
       " 415,\n",
       " 930,\n",
       " 1442,\n",
       " 2469,\n",
       " 2470,\n",
       " 424,\n",
       " 938,\n",
       " 1453,\n",
       " 432,\n",
       " 433,\n",
       " 1970,\n",
       " 2482,\n",
       " 436,\n",
       " 1973,\n",
       " 1974,\n",
       " 1465,\n",
       " 1977,\n",
       " 1978,\n",
       " 1979,\n",
       " 1469,\n",
       " 1980,\n",
       " 1981,\n",
       " 1472,\n",
       " 1982,\n",
       " 1986,\n",
       " 1987,\n",
       " 1988,\n",
       " 1989,\n",
       " 1990,\n",
       " 1991,\n",
       " 1992,\n",
       " 968,\n",
       " 1994,\n",
       " 1995,\n",
       " 460,\n",
       " 973,\n",
       " 1993,\n",
       " 1996,\n",
       " 2000,\n",
       " 1997,\n",
       " 1998,\n",
       " 2001,\n",
       " 2002,\n",
       " 2003,\n",
       " 2004,\n",
       " 2007,\n",
       " 2008,\n",
       " 2009,\n",
       " 2005,\n",
       " 2006,\n",
       " 476,\n",
       " 2520,\n",
       " 477,\n",
       " 1494,\n",
       " 2016,\n",
       " 2010,\n",
       " 483,\n",
       " 1510,\n",
       " 809,\n",
       " 2025,\n",
       " 1514,\n",
       " 490,\n",
       " 2027,\n",
       " 498,\n",
       " 1526,\n",
       " 503,\n",
       " 1017,\n",
       " 507,\n",
       " 1023]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 414)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(node_color), len(node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView((2, 13, 14, 27, 2084, 38, 41, 45, 2095, 49, 55, 60, 2112, 68, 69, 71, 2120, 2122, 2130, 85, 86, 88, 94, 2144, 102, 104, 109, 112, 2165, 2166, 118, 126, 133, 137, 139, 141, 2189, 146, 2195, 2194, 151, 153, 158, 159, 160, 2210, 2211, 164, 175, 179, 181, 2230, 201, 210, 215, 218, 2268, 224, 2274, 230, 232, 2291, 2301, 2302, 255, 2303, 2304, 2309, 267, 2316, 2318, 2319, 2320, 2321, 279, 2330, 2331, 285, 2360, 2361, 314, 317, 2367, 2371, 331, 332, 334, 335, 2388, 350, 351, 356, 366, 377, 382, 383, 384, 388, 2436, 391, 397, 398, 401, 2450, 407, 409, 411, 415, 417, 435, 446, 452, 454, 459, 460, 471, 476, 481, 482, 506, 510, 511, 2559, 514, 516, 519, 530, 531, 542, 549, 554, 556, 566, 568, 576, 581, 589, 594, 596, 604, 608, 617, 644, 660, 661, 663, 673, 674, 678, 681, 691, 695, 711, 712, 716, 717, 719, 733, 743, 745, 759, 767, 778, 779, 790, 791, 792, 794, 795, 808, 818, 827, 830, 835, 836, 841, 842, 860, 862, 863, 864, 880, 887, 897, 899, 908, 910, 921, 948, 955, 962, 963, 968, 980, 1002, 1004, 1012, 1023, 1026, 1029, 1062, 1065, 1079, 1095, 1096, 1107, 1120, 1121, 1127, 1144, 1149, 1160, 1166, 1192, 1196, 1251, 1265, 1270, 1273, 1293, 1294, 1299, 1309, 1319, 1329, 1331, 1333, 1336, 1343, 1348, 1359, 1362, 1394, 1403, 1434, 1448, 1453, 1464, 1485, 1497, 1505, 1507, 1521, 1525, 1529, 1538, 1539, 1558, 1560, 1561, 1574, 1576, 1581, 1583, 1592, 1614, 1616, 1624, 1625, 1626, 1633, 1644, 1645, 1654, 1661, 1665, 1666, 1668, 1671, 1674, 1675, 1676, 1681, 1682, 1690, 1697, 1699, 1704, 1705, 1709, 1729, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1790, 1807, 1808, 1809, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1859, 1869, 1870, 1873, 1875, 1876, 1889, 1891, 1894, 1905, 1906, 1907, 1908, 1909, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1929, 1968, 1976, 1983, 1984, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2030, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2045, 1, 1454, 1701, 1810, 2034, 2075, 2077, 2668, 606, 2578, 306, 429, 1219, 2667, 135, 2145, 2329, 2504, 323, 651, 771, 787, 815, 1156, 2020, 2021, 37, 1527, 1358, 1013, 1351, 1926, 206, 2691, 33, 442, 665, 2637, 91, 196, 627, 1051, 2066, 2121, 2123, 430, 912, 983, 1261, 1890, 2127, 2249, 2487, 2488, 2295, 76, 130, 162, 300, 498, 696, 737, 851, 1174, 1288, 1494, 1658, 1677, 1713, 1732, 1741, 1882, 2012, 2013, 2014, 2015, 2016, 2017, 2178, 2394, 195, 586, 675, 934, 1649, 1966, 2263, 2355, 2357, 2490, 1623, 1871, 1878, 2256, 124, 176, 236, 289, 318, 426, 563, 610, 1045, 1337, 1346, 1789, 1805, 2092, 2093, 2094, 487, 2080, 1551, 2079, 399, 1670, 2082, 18, 103, 740, 847, 1395, 1468, 1927, 2059, 214, 324, 2193, 2236, 2238, 2335, 180, 2308, 277, 553, 2356, 211, 2135, 2217, 197, 231, 1683, 938, 2296, 24, 297, 570, 598, 2430, 781, 1020, 1382, 2076, 2091, 2119, 2594, 309, 1278, 1370, 1441, 577, 1217, 869, 1864, 715, 2233, 2292, 1692, 1266, 2541, 465, 469, 2385, 461, 994, 1021, 1043, 1268, 1399, 670, 2373, 2266, 32, 242, 270, 304, 502, 666, 838, 1195, 2280, 2344, 2423, 861, 2203, 2027, 15, 395, 765, 894, 1090, 1093, 1147, 1271, 1598, 2177, 2368, 2369, 2370, 2480, 2615, 95, 693, 551, 728, 945, 1377, 302, 308, 406, 656, 1640, 2085, 2089, 2090, 1259, 2018, 2116, 191, 1203, 1899, 2497, 989, 2031, 493, 2365, 879, 730, 54, 389, 562, 704, 754, 969, 1077, 1284, 1412, 1620, 1743, 2113, 1488, 1577, 2609, 204, 525, 593, 966, 2182, 1072, 2494, 486, 1912, 903, 1258, 441, 973, 2022, 2188, 2190, 2532, 10, 1140, 1800, 823, 1287, 2307, 1352, 1131, 1171, 120, 478, 1314, 1978, 2104, 387, 416, 484, 1245, 685, 1116, 1223, 503, 574, 2348, 1792, 121, 1158, 496, 992, 1652, 2109, 705, 97, 344, 807, 935, 1028, 1353, 1879, 1880, 1881, 1883, 1884, 1885, 1445, 1446, 252, 414, 539, 1285, 2111, 850, 603, 2409, 303, 1239, 1570, 1703, 873, 2314, 1224, 702, 1973, 171, 1548, 2555, 1590, 638, 924, 2383, 1039, 1921, 2100, 1134, 708, 1572, 2078, 2403, 87, 161, 1427, 1758, 239, 1152, 1410, 1055, 1858, 772, 2134, 2293, 1482, 1806, 29, 43, 203, 258, 375, 706, 805, 1094, 1141, 1157, 1417, 1443, 2240, 2399, 2400, 2401, 2434, 1603, 1367, 622, 1952, 2033, 1489, 1797, 2568, 916, 1303, 2531, 1218, 298, 1325, 2613, 605, 2243, 2379, 1110, 2025, 1655, 2136, 985, 2582, 1621, 943, 1061, 2300, 505, 1622, 722, 1111, 1119, 2124, 2125, 2126, 2129, 65, 2418, 352, 61, 490, 995, 1338, 2102, 2103, 186, 78, 310, 749, 2312, 1452, 2032, 2163, 2605, 2278, 1372, 2137, 2317, 445, 262, 36, 330, 773, 1146, 1552, 1801, 2086, 2107, 98, 1115, 1178, 2350, 643, 747, 1133, 1500, 2185, 1014, 1191, 2338, 2339, 2340, 1066, 376, 2071, 2485, 56, 412, 447, 1402, 2050, 1567, 1615, 48, 1662, 2381, 355, 891, 2608, 1074, 1501, 1975, 1522, 2253, 1193, 1289, 2081, 2322, 1738, 1739, 657, 1568, 1837, 2325, 544, 1564, 138, 337, 960, 1282, 1283, 1499, 1735, 2324, 2143, 2327, 1798, 2326, 2096, 1015, 1609, 579, 2550, 1424, 1950, 829, 2305, 2306, 1948, 316, 1126, 408, 734, 736, 2056, 816, 1979, 1980, 2281, 2405, 868, 2276, 1867, 2117, 325, 1376, 2419, 1487, 199, 205, 420, 1097, 157, 1531, 1892, 1893, 229, 261, 536, 770, 1049, 1215, 1405, 1479, 1508, 2118, 1964, 1474, 2649, 907, 1535, 2457, 2310, 2422, 2653, 147, 438, 1295, 2509, 396, 1185, 849, 169, 8, 327, 2063, 2064, 1347, 2412, 1197, 2044, 2378, 2380, 185, 746, 2477, 25, 1324, 833, 293, 788, 341, 699, 1248, 1651, 1791, 1830, 1852, 1856, 2026, 2046, 2047, 2048))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Val Acc: 0.7260 Test Acc: 0.7140 Best l: 16 Best a: 0.99\n"
     ]
    }
   ],
   "source": [
    "# dataset = citeseer\n",
    "# dataset = cora\n",
    "dataset = pubmed\n",
    "\n",
    "best_val_acc = final_test_acc = 0\n",
    "best_l = best_a = 0\n",
    "\n",
    "for l in [1, 2, 4, 8, 16, 32]:\n",
    "    for a in [0.05, 0.1, 0.3, 0.6, 0.8, 0.9, 0.95, 0.99, 1]:\n",
    "        model = LP(num_layers=l, alpha=a)\n",
    "        outs = model.train(dataset)\n",
    "        train_acc, val_acc, tmp_test_acc = model.test()\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            test_acc = tmp_test_acc\n",
    "            best_l = l\n",
    "            best_a = a\n",
    "            \n",
    "print(f'Best Val Acc: {best_val_acc:.4f}', f'Test Acc: {test_acc:.4f}', f'Best l: {best_l}', f'Best a: {best_a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8833333333333333, 0.712, 0.707]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = model.test()\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19717, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0,  ..., 2, 0, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0,  ..., 2, 0, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fe8eaf950b0cf64c1b70de22759d9a144a2595c541b4003711edd1f96d908e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
